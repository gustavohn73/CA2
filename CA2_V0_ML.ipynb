{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a2b37d-661a-4bec-84fc-6803d3f4519c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e79a4e90-9825-447a-ae88-c93f9505717c",
   "metadata": {},
   "source": [
    "http://localhost:8890/lab!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install nltk\n",
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab86713-fd1a-4530-bbf1-218b9c04a44b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1089dd83-4193-43ae-ad4c-fda87e659897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,tweepy,csv,re, requests, json\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path, time, re\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d86504-3bc1-443b-8827-e0f0e5e3291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30cfb27-cb88-4c26-9801-2f4e55e9cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # We can suppress the warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf0efa-7921-4ea7-a523-9661f26befd5",
   "metadata": {},
   "source": [
    "# Getting Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5af613",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71e18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token\n",
    "config = dotenv_values(\".env\")\n",
    "bearer_token = config['BEARER_TOKEN']\n",
    "\n",
    "#connections\n",
    "auth = tweepy.OAuth2BearerHandler({bearer_token})\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def get_tweet_v1(query, filename, max_n):\n",
    "    search_url = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "\n",
    "\n",
    "    file_name = f'{filename}.bz2'\n",
    "    \n",
    "    if os.path.exists(file_name) == False: #First checking if database exists\n",
    "        print(f'Getting tweets...')\n",
    "        \n",
    "        # Querying the API\n",
    "        json_response = connect_to_endpoint(search_url, query)\n",
    "        \n",
    "        tweets_dt = pd.DataFrame.from_dict(json_response['data'])\n",
    "        \n",
    "        try:\n",
    "            n_token = json_response['meta'][\"next_token\"]\n",
    "            n = 0\n",
    "            while n_token != 0 | n < max_n:\n",
    "                print(f'Next Token: {n} \\n {n_token}')\n",
    "                query_next = query\n",
    "                query_next['next_token'] = n_token\n",
    "                json_response = connect_to_endpoint(search_url, query_next)\n",
    "                tweets_n = pd.DataFrame.from_dict(json_response['data'])\n",
    "                tweets_dt = pd.concat([tweets_dt,tweets_n], ignore_index=True)\n",
    "\n",
    "                n += 1\n",
    "                n_token = json_response['meta'][\"next_token\"]\n",
    "\n",
    "        except:\n",
    "            print('Error to proceed')\n",
    "            \n",
    "        meta = json_response['meta']\n",
    "        np.save(f'{filename}.npy', meta)\n",
    "        print ('file Meta Saved')\n",
    " \n",
    "        tweets_dt.to_csv(file_name, index=False,compression='bz2')\n",
    "        print(f'{len(tweets_dt)} Tweets found and saved')\n",
    "        \n",
    "    else:\n",
    "        create_dt = time.strftime(\"%d/%m/%Y %H:%M:%S\",time.strptime(time.ctime(os.path.getmtime(file_name))))\n",
    "        print(f'Reading {file_name}, created at {create_dt}')\n",
    "        tweets_dt = pd.read_csv(file_name)\n",
    "        print(f'File with {len(tweets_dt)} Tweets')\n",
    "        \n",
    "    return tweets_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0568d7",
   "metadata": {},
   "source": [
    "### Countries\n",
    "\n",
    "Getting up to 1000 tweets each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5bc5298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading tweets_agri.bz2, created at 23/12/2022 16:37:52\n",
      "File with 1027 Tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Agricultural apprentices from our Rosewarne ca...</td>\n",
       "      <td>1604838229684920324</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604838229684920324</td>\n",
       "      <td>21294093</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604838229684920324']</td>\n",
       "      <td>2022-12-19T13:57:05.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>\"Von der Leyen has signed an agreement between...</td>\n",
       "      <td>1604586138496294919</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604586138496294919</td>\n",
       "      <td>1434697221967163393</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604586138496294919']</td>\n",
       "      <td>2022-12-18T21:15:21.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'type': 'quoted', 'id': '1604382370664169473'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Currency 1940 France 50 Francs Banknote P-85b ...</td>\n",
       "      <td>1605664417785733121</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605664417785733121</td>\n",
       "      <td>1456028517930442755</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605664417785733121']</td>\n",
       "      <td>2022-12-21T20:40:03.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "916  Agricultural apprentices from our Rosewarne ca...  1604838229684920324   \n",
       "652  \"Von der Leyen has signed an agreement between...  1604586138496294919   \n",
       "351  Currency 1940 France 50 Francs Banknote P-85b ...  1605664417785733121   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "916   en       everyone  1604838229684920324             21294093   \n",
       "652   en       everyone  1604586138496294919  1434697221967163393   \n",
       "351   en       everyone  1605664417785733121  1456028517930442755   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "916  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "652  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "351  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "916  ['1604838229684920324']  2022-12-19T13:57:05.000Z                  NaN   \n",
       "652  ['1604586138496294919']  2022-12-18T21:15:21.000Z                  NaN   \n",
       "351  ['1605664417785733121']  2022-12-21T20:40:03.000Z                  NaN   \n",
       "\n",
       "                                     referenced_tweets  geo country  \n",
       "916                                                NaN  NaN      UK  \n",
       "652  [{'type': 'quoted', 'id': '1604382370664169473'}]  NaN  German  \n",
       "351                                                NaN  NaN  France  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = ['Europe', 'Ireland', 'Portugal', 'France', 'German', 'UK']\n",
    "filename = 'tweets_agri.bz2'\n",
    "\n",
    "if os.path.exists(filename) == False: \n",
    "    for c in countries:\n",
    "\n",
    "        q = {\n",
    "        'query': f'agriculture {c} -is:retweet',\n",
    "        'max_results': 100,\n",
    "        'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "        'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "        'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "        'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "        }\n",
    "\n",
    "        fn = f'tweets_{c}'\n",
    "        t = get_tweet_v1(q, fn, 10)\n",
    "        t['country'] = c\n",
    "        if c == countries[0]:\n",
    "            tweets = t\n",
    "        else:\n",
    "            tweets = pd.concat([tweets, t], ignore_index=True)\n",
    "\n",
    "    tweets.to_csv(filename, index=False,compression='bz2')\n",
    "    print(f'File with {len(tweets)} saved.')\n",
    "\n",
    "else:\n",
    "    create_dt = time.strftime(\"%d/%m/%Y %H:%M:%S\",time.strptime(time.ctime(os.path.getmtime(filename))))\n",
    "    print(f'Reading {filename}, created at {create_dt}')\n",
    "    tweets = pd.read_csv(filename)\n",
    "    print(f'File with {len(tweets)} Tweets')\n",
    "    \n",
    "\n",
    "tweets.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aeddaa-cefe-4e2e-8de2-2da07673ba09",
   "metadata": {},
   "source": [
    "# Clean Your Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead89be-b008-457a-b756-743f9679d0a6",
   "metadata": {},
   "source": [
    "## Worlds extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77d4845-61f5-473f-8c7d-10007e17c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(x, link, keyword, usernames):\n",
    "    list_of_lists =[]\n",
    "    if link == True:\n",
    "        list_of_links = []\n",
    "        words = x.split(' ')\n",
    "        for word in words:\n",
    "            if re.search('http', word):\n",
    "                list_of_links.append(re.split(\"\\W+\",word.lower()))\n",
    "        if len(list_of_links) > 0:\n",
    "            list_of_lists.append(list_of_links[0])\n",
    "    \n",
    "    if keyword == True:\n",
    "        list_of_keywords = []\n",
    "        words = x.split()\n",
    "        for word in words:\n",
    "            if word.startswith('#'):\n",
    "                list_of_keywords.append(word)\n",
    "        if len(list_of_keywords) > 0:\n",
    "            list_of_lists.append(list_of_keywords)\n",
    "            \n",
    "    if usernames == True:\n",
    "        list_of_usernames = []\n",
    "        words = x.split()\n",
    "        for word in words:\n",
    "            if word.startswith('@'):\n",
    "                list_of_usernames.append(word.lower().replace('@',''))\n",
    "        if len(list_of_usernames) > 0:\n",
    "            list_of_lists.append(list_of_usernames)\n",
    "    \n",
    "    return  [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "        \n",
    "# keyword extraction from tweets\n",
    "def get_keywords(x):\n",
    "    list_of_keywords = []\n",
    "    words = x.split()\n",
    "    for word in words:\n",
    "        if word.startswith('#'):\n",
    "            list_of_keywords.append(word)\n",
    "    return list_of_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95cdfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets.lang == 'en']\n",
    "tweets = tweets.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e75c4a2-c05a-4c40-96fb-e4a875f809bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = tweets['text'].apply(lambda tweet : clean_tweet(tweet, link = True, keyword = False, usernames = True))\n",
    "rem_list = [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "tweets['text_c'] = tweets['text'].apply( lambda tweet : ' '.join([word for word in re.split(\"\\W+\",tweet) if word.lower() not in rem_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cf3a80-7754-49f6-ad1e-abc74bd2a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keywords'] = tweets['text'].apply( lambda tweet : get_keywords(tweet) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8954d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Great to see collaboration between Ireland and...</td>\n",
       "      <td>1605624144279765000</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605624144279765000</td>\n",
       "      <td>923680495405293569</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605624144279765000']</td>\n",
       "      <td>2022-12-21T18:00:01.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Great to see collaboration between Ireland New...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Lyxor Bloomberg Equal-weight Commodity ex-Agri...</td>\n",
       "      <td>1606204264581300225</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1606204264581300225</td>\n",
       "      <td>42410755</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1606204264581300225']</td>\n",
       "      <td>2022-12-23T08:25:13.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>Lyxor Bloomberg Equal weight Commodity ex UCIT...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "125  Great to see collaboration between Ireland and...  1605624144279765000   \n",
       "305  Lyxor Bloomberg Equal-weight Commodity ex-Agri...  1606204264581300225   \n",
       "\n",
       "    lang reply_settings                   id           author_id  \\\n",
       "125   en       everyone  1605624144279765000  923680495405293569   \n",
       "305   en       everyone  1606204264581300225            42410755   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "125  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "305  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "125  ['1605624144279765000']  2022-12-21T18:00:01.000Z                  NaN   \n",
       "305  ['1606204264581300225']  2022-12-23T08:25:13.000Z                  NaN   \n",
       "\n",
       "    referenced_tweets  geo  country  \\\n",
       "125               NaN  NaN  Ireland   \n",
       "305               NaN  NaN       UK   \n",
       "\n",
       "                                                text_c keywords  \n",
       "125  Great to see collaboration between Ireland New...       []  \n",
       "305  Lyxor Bloomberg Equal weight Commodity ex UCIT...       []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aacee4f-7872-4d82-9c7d-e26b40459c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD:  @Nien72521217 @divyanshu3pathi The per Capita story doesn't correlate\n",
      "\n",
      "When I see 1000 AD, W Europe didn't have trade routes established, didn't have industrial revolution. Had largely constrained agriculture due to nature of their land. No known irrigation projects.\n",
      "\n",
      "Yet the per Capita is high? \n",
      "\n",
      "NEW:  per Capita story doesn correlate When I see 1000 AD W Europe didn have routes established didn have industrial revolution Had largely constrained due to nature of their land No known irrigation projects Yet per Capita is high\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "print('OLD: ', tweets['text'][n], '\\n')\n",
    "print('NEW: ', tweets['text_c'][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05495ec4-c735-4de4-ac3c-97ec5336f5aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PoterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d017ded-762a-4d2e-83a1-5c77ddd7a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the stopwords into the object named as \"stop_words\"\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Store the string.punctuation into an object punct\n",
    "punct = string.punctuation\n",
    "\n",
    "# Initialise an object using a method PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f436cc-944d-421b-9e5f-b0d8b9db2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stremming(df, text_col, name_new_col):\n",
    "    # Store the column of the dataframe named as \"text\"\n",
    "    X = df[text_col]\n",
    "    cleaned_data=[]\n",
    "    # For loop from first value to length(X), ^a-zA-Z means include small and capital case letters\n",
    "    for i in range(len(X)):\n",
    "        text = re.sub('[^a-zA-Z]', ' ', X.iloc[i])\n",
    "        text = text.lower().split()\n",
    "        text = [stemmer.stem(word) for word in text if (word not in stop_words) and (word not in punct)]\n",
    "        text = ' '.join(text)\n",
    "        df.loc[ i ,name_new_col] = text\n",
    "    print('Stremmer done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4daa44e1-e9b6-45e9-9558-4ed03ce04eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stremmer done!\n"
     ]
    }
   ],
   "source": [
    "stremming(tweets, 'text_c', 'text_ps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bf02984-820b-4a28-8f1a-dd801d25c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knowledge of how to make pottery spread like wildfire between the hunter-gatherers of Stone Age Europe, covering thousands of miles in a few hundred years, much faster than agriculture https://t.co/Iu2YACvIGN \n",
      "\n",
      "knowledg make potteri spread like wildfir hunter gather stone age europ cover thousand mile hundr much faster \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tweets['text'][0], '\\n')\n",
    "print(tweets['text_ps'][0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75f0ff-efcc-4bc1-8f83-5cfe08074244",
   "metadata": {},
   "source": [
    "# Sentiment Analyzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c6b817-f690-4816-9bb7-eca288a23508",
   "metadata": {},
   "source": [
    "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. [link](https://textblob.readthedocs.io/en/dev/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3597f8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Profresh prevents heating and #feed deteriorat...</td>\n",
       "      <td>1604870236565635075</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604870236565635075</td>\n",
       "      <td>1650441565</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604870236565635075']</td>\n",
       "      <td>2022-12-19T16:04:16.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Profresh prevents heating feed deterioration i...</td>\n",
       "      <td>[#feed, #grains, #animal, #silage, #agricultur...</td>\n",
       "      <td>profresh prevent heat feed deterior store grai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>To mark UN International Migrants Day (18th De...</td>\n",
       "      <td>1604402086778634241</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604402086778634241</td>\n",
       "      <td>2242507148</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604402086778634241']</td>\n",
       "      <td>2022-12-18T09:04:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>To mark UN International Migrants Day 18th Dec...</td>\n",
       "      <td>[#MigrantsDay]</td>\n",
       "      <td>mark un intern migrant day th dec partner deve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "82   Profresh prevents heating and #feed deteriorat...  1604870236565635075   \n",
       "588  To mark UN International Migrants Day (18th De...  1604402086778634241   \n",
       "\n",
       "    lang reply_settings                   id   author_id  \\\n",
       "82    en       everyone  1604870236565635075  1650441565   \n",
       "588   en       everyone  1604402086778634241  2242507148   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "82   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "588  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "82   ['1604870236565635075']  2022-12-19T16:04:16.000Z                  NaN   \n",
       "588  ['1604402086778634241']  2022-12-18T09:04:00.000Z                  NaN   \n",
       "\n",
       "    referenced_tweets  geo country  \\\n",
       "82                NaN  NaN  Europe   \n",
       "588               NaN  NaN      UK   \n",
       "\n",
       "                                                text_c  \\\n",
       "82   Profresh prevents heating feed deterioration i...   \n",
       "588  To mark UN International Migrants Day 18th Dec...   \n",
       "\n",
       "                                              keywords  \\\n",
       "82   [#feed, #grains, #animal, #silage, #agricultur...   \n",
       "588                                     [#MigrantsDay]   \n",
       "\n",
       "                                               text_ps  \n",
       "82   profresh prevent heat feed deterior store grai...  \n",
       "588  mark un intern migrant day th dec partner deve...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6f0424-270d-4d33-a4d2-a561f9dc4d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Plan to boost productivity &amp;amp; innovation in...</td>\n",
       "      <td>1605601518371094528</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605601518371094528</td>\n",
       "      <td>1393216141502386176</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605601518371094528']</td>\n",
       "      <td>2022-12-21T16:30:07.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>Plan to boost productivity amp innovation in l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>plan boost product amp innov launch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>🌱 @esa, @DLR_en &amp;amp; the German Federal Offic...</td>\n",
       "      <td>1604431341143171073</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604431341143171073</td>\n",
       "      <td>4918687943</td>\n",
       "      <td>{'retweet_count': 8, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604431341143171073']</td>\n",
       "      <td>2022-12-18T11:00:15.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "      <td>esa amp German Federal Office of Food BLE orga...</td>\n",
       "      <td>[#Agrifood, #IGW2023.]</td>\n",
       "      <td>esa amp german feder offic food ble organis sp...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "380  Plan to boost productivity &amp; innovation in...  1605601518371094528   \n",
       "269  🌱 @esa, @DLR_en &amp; the German Federal Offic...  1604431341143171073   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "380   en       everyone  1605601518371094528  1393216141502386176   \n",
       "269   en       everyone  1604431341143171073           4918687943   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "380  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "269  {'retweet_count': 8, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "380  ['1605601518371094528']  2022-12-21T16:30:07.000Z                  NaN   \n",
       "269  ['1604431341143171073']  2022-12-18T11:00:15.000Z                  NaN   \n",
       "\n",
       "    referenced_tweets  geo country  \\\n",
       "380               NaN  NaN      UK   \n",
       "269               NaN  NaN  German   \n",
       "\n",
       "                                                text_c  \\\n",
       "380  Plan to boost productivity amp innovation in l...   \n",
       "269  esa amp German Federal Office of Food BLE orga...   \n",
       "\n",
       "                   keywords  \\\n",
       "380                      []   \n",
       "269  [#Agrifood, #IGW2023.]   \n",
       "\n",
       "                                               text_ps  TextBlob   Vader  \n",
       "380                plan boost product amp innov launch       0.0  0.4019  \n",
       "269  esa amp german feder offic food ble organis sp...      -0.1  0.2960  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tweets.index:\n",
    "    text = tweets.loc[i,'text_ps']\n",
    "    tweets.loc[i, 'TextBlob'] = TextBlob(text).sentiment.polarity\n",
    "    #print(TextBlob(text).sentiment.polarity)\n",
    "    tweets.loc[i, 'Vader'] = SentimentIntensityAnalyzer().polarity_scores(text)['compound']\n",
    "    #print(SentimentIntensityAnalyzer().polarity_scores(text)['compound'], '\\n')\n",
    "    \n",
    "tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20692767-6953-4c5a-afc3-c572133f1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(df, col):\n",
    "\n",
    "    polarity = 0\n",
    "    neutral = 0\n",
    "    wpositive = 0\n",
    "    positive = 0\n",
    "    spositive = 0\n",
    "    wnegative = 0\n",
    "    negative = 0\n",
    "    snegative = 0\n",
    "     \n",
    "    for t in df.index:\n",
    "        \n",
    "        v = df.loc[t, col]\n",
    "        polarity += v  # adding up polarities to find the average later\n",
    "\n",
    "        if (v == 0):  # adding reaction of how people are reacting to find average later\n",
    "            neutral += 1\n",
    "            desc = 'neutral'\n",
    "        elif (v > 0 and v <= 0.3):\n",
    "            wpositive += 1\n",
    "            desc ='weak_positive'\n",
    "        elif (v > 0.3 and v <= 0.6):\n",
    "            positive += 1\n",
    "            desc = 'positive'\n",
    "        elif (v > 0.6 and v <= 1):\n",
    "            spositive += 1\n",
    "            desc = 'strong_positive'\n",
    "        elif (v > -0.3 and v <= 0):\n",
    "            wnegative += 1\n",
    "            desc = 'weak_negative'\n",
    "        elif (v > -0.6 and v <= -0.3):\n",
    "            negative += 1\n",
    "            desc = 'negative'\n",
    "        elif (v > -1 and v <= -0.6):\n",
    "            snegative += 1\n",
    "            desc = 'strong_negative'\n",
    "         \n",
    "        df.loc[t, f'{col}_desc'] = desc\n",
    "        \n",
    "\n",
    "    return {'polarity_sum':polarity,\n",
    "            'polarity_mean':(polarity / len(df)),\n",
    "            'neutral':neutral,\n",
    "            'strong_positive':spositive,\n",
    "            'positive':positive,\n",
    "            'weak_positive':wpositive,\n",
    "            'weak_negative':wnegative,\n",
    "            'negative':negative,\n",
    "            'strong_negative':snegative}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a9864e-2155-4fc0-9154-82d2544a2da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity_sum': 43.62266860916862,\n",
       " 'polarity_mean': 0.06837408872910442,\n",
       " 'neutral': 265,\n",
       " 'strong_positive': 18,\n",
       " 'positive': 68,\n",
       " 'weak_positive': 174,\n",
       " 'weak_negative': 91,\n",
       " 'negative': 13,\n",
       " 'strong_negative': 8}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_polarity(tweets,'TextBlob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ccdc01-f6c2-4a3f-9e1a-ea8688effb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity_sum': 109.63159999999992,\n",
       " 'polarity_mean': 0.1718363636363635,\n",
       " 'neutral': 209,\n",
       " 'strong_positive': 99,\n",
       " 'positive': 154,\n",
       " 'weak_positive': 70,\n",
       " 'weak_negative': 39,\n",
       " 'negative': 42,\n",
       " 'strong_negative': 25}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_polarity(tweets,'Vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db5c2e3c-a707-450f-bb85-c7327834ad00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob_desc</th>\n",
       "      <th>Vader_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>@CrocketLawncha @FinanzamtBayern @GreenTextRep...</td>\n",
       "      <td>1605692513083215872</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605723727035092994</td>\n",
       "      <td>1411339294933913602</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>['1605723727035092994']</td>\n",
       "      <td>2022-12-22T00:35:44.000Z</td>\n",
       "      <td>9.096129e+17</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '160572336195436...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "      <td>bro there were lions every where than 50 giant...</td>\n",
       "      <td>[]</td>\n",
       "      <td>bro lion everi giant mammal america none exist...</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weak_negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text      conversation_id  \\\n",
       "42  @CrocketLawncha @FinanzamtBayern @GreenTextRep...  1605692513083215872   \n",
       "\n",
       "   lang reply_settings                   id            author_id  \\\n",
       "42   en       everyone  1605723727035092994  1411339294933913602   \n",
       "\n",
       "                                       public_metrics  \\\n",
       "42  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
       "\n",
       "     edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "42  ['1605723727035092994']  2022-12-22T00:35:44.000Z         9.096129e+17   \n",
       "\n",
       "                                    referenced_tweets  geo country  \\\n",
       "42  [{'type': 'replied_to', 'id': '160572336195436...  NaN  Europe   \n",
       "\n",
       "                                               text_c keywords  \\\n",
       "42  bro there were lions every where than 50 giant...       []   \n",
       "\n",
       "                                              text_ps  TextBlob  Vader  \\\n",
       "42  bro lion everi giant mammal america none exist... -0.133333    0.0   \n",
       "\n",
       "    TextBlob_desc Vader_desc  \n",
       "42  weak_negative    neutral  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "257a80b8-1d52-4e9e-9094-1c9dfe9114c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Original: @RonFilipkowski Ron, you are missing the point.  Putin doesn’t want peace, Putin wants Ukraine’s oil, gas and agriculture (wheat) to have a stranglehold on Europe!!! \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Clear: Ron you missing point Putin doesn want peace Putin wants s oil gas wheat to have a stranglehold on Europe \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Steammed: ron miss point putin want peac putin want oil ga wheat stranglehold europ \n",
      " -------------------------------------------------------------------------------------------\n",
      "KeyWords: [] \n",
      " -------------------------------------------------------------------------------------------\n",
      "TextBlob:  0.0 neutral\n",
      "Vader:  0.0 neutral\n"
     ]
    }
   ],
   "source": [
    "##Checking Twitters\n",
    "\n",
    "n = 3\n",
    "print('Text Original:', tweets.loc[n, 'text'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "print('Text Clear:', tweets.loc[n, 'text_c'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('Text Steammed:', tweets.loc[n, 'text_ps'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('KeyWords:', tweets.loc[n, 'keywords'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('TextBlob: ',tweets.loc[n, 'TextBlob'], tweets.loc[n, 'TextBlob_desc'])\n",
    "print('Vader: ', tweets.loc[n, 'Vader'], tweets.loc[n, 'Vader_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8add63f-2230-4811-941a-d4fd1e8ea7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob_desc</th>\n",
       "      <th>Vader_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>knowledg make potteri spread like wildfir hunt...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>per capita stori correl see ad w europ rout es...</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>everyth need chang villag settl illo tempor hu...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>neutral</td>\n",
       "      <td>strong_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>ron miss point putin want peac putin want oil ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>russia one encourag us aid amp assist help peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>[]</td>\n",
       "      <td>ye reform set safe amp legal rout process refu...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>positive</td>\n",
       "      <td>strong_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>[#BiggestJobonEarth, #agriculture]</td>\n",
       "      <td>case miss catch episod biggestjobonearth podca...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>negative</td>\n",
       "      <td>weak_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>[]</td>\n",
       "      <td>respons contribut transform new strategi</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>[]</td>\n",
       "      <td>eu minist call rethink free</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>[#RemoteSensing, #ComputerScience, #hyperspect...</td>\n",
       "      <td>posit predict model hyperspectr satellit imag ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              keywords  \\\n",
       "0                                                   []   \n",
       "1                                                   []   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "633                                                 []   \n",
       "634                 [#BiggestJobonEarth, #agriculture]   \n",
       "635                                                 []   \n",
       "636                                                 []   \n",
       "637  [#RemoteSensing, #ComputerScience, #hyperspect...   \n",
       "\n",
       "                                               text_ps  TextBlob   Vader  \\\n",
       "0    knowledg make potteri spread like wildfir hunt...  0.200000  0.3612   \n",
       "1    per capita stori correl see ad w europ rout es...  0.017500  0.0000   \n",
       "2    everyth need chang villag settl illo tempor hu...  0.000000  0.7717   \n",
       "3    ron miss point putin want peac putin want oil ...  0.000000  0.0000   \n",
       "4    russia one encourag us aid amp assist help peo...  0.000000  0.4019   \n",
       "..                                                 ...       ...     ...   \n",
       "633  ye reform set safe amp legal rout process refu...  0.350000  0.8689   \n",
       "634  case miss catch episod biggestjobonearth podca... -0.500000  0.1531   \n",
       "635           respons contribut transform new strategi  0.136364  0.0000   \n",
       "636                        eu minist call rethink free  0.400000  0.5106   \n",
       "637  posit predict model hyperspectr satellit imag ...  0.000000  0.0000   \n",
       "\n",
       "     TextBlob_desc       Vader_desc  \n",
       "0    weak_positive         positive  \n",
       "1    weak_positive          neutral  \n",
       "2          neutral  strong_positive  \n",
       "3          neutral          neutral  \n",
       "4          neutral         positive  \n",
       "..             ...              ...  \n",
       "633       positive  strong_positive  \n",
       "634       negative    weak_positive  \n",
       "635  weak_positive          neutral  \n",
       "636       positive         positive  \n",
       "637        neutral          neutral  \n",
       "\n",
       "[638 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[:, -6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e7c79-0879-49b5-89f8-22752f114ae9",
   "metadata": {},
   "source": [
    "## Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3f3bff5-51d0-4991-bac3-4f6f98cfc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "807c9b2e-6cc2-467d-8c8e-25a30ea4a224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13446</th>\n",
       "      <td>hillary clinton wows russians with poignant ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "13446  hillary clinton wows russians with poignant ch...             1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('sarcasm_headlines.bz2')\n",
    "news.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "144ff0f9-d5f9-4a1a-bc6b-1937bfcda176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline        False\n",
      "is_sarcastic    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(news.isnull().any(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8c5cabd-ac81-4f61-bd88-8532fba63e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stremmer done!\n"
     ]
    }
   ],
   "source": [
    "stremming(news, 'headline', 'headline_ps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a35696a6-e876-4c86-99c8-28c31e2f7156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline_ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13845</th>\n",
       "      <td>woman probably just made up rape story in orde...</td>\n",
       "      <td>1</td>\n",
       "      <td>woman probabl made rape stori order get threat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>25-pound ham wedged in parents' refrigerator</td>\n",
       "      <td>1</td>\n",
       "      <td>pound ham wedg parent refriger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic  \\\n",
       "13845  woman probably just made up rape story in orde...             1   \n",
       "12416       25-pound ham wedged in parents' refrigerator             1   \n",
       "\n",
       "                                             headline_ps  \n",
       "13845  woman probabl made rape stori order get threat...  \n",
       "12416                     pound ham wedg parent refriger  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89da3d5f-ade0-4bbb-9347-27fda1d84d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, col, max_feat):\n",
    "    features = df[col]\n",
    "\n",
    "    # vectorizing the data with maximum features\n",
    "    tv = TfidfVectorizer(max_features = max_feat)\n",
    "    features = list(features)\n",
    "    features = tv.fit_transform(features).toarray()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6eadf98f-4d8c-4ba3-8db8-6435afb36ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = create_features(news, 'headline_ps', 3300)\n",
    "labels = news['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56eacc4a-5c35-4830-89b3-8657354f2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2d6160f-3ab9-45f9-99c1-58a414f2f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Support Vector Classifier:\n",
      "Train:  0.8462933039057265\n",
      "Test:  0.7784431137724551\n",
      "\n",
      "Gaussuan Naive Bayes:\n",
      "Train:  0.750679856540417\n",
      "Test:  0.7215568862275449\n",
      "\n",
      "Logistic Regression:\n",
      "Train:  0.8314349899499468\n",
      "Test:  0.782185628742515\n",
      "\n",
      "Random Forest Classifier:\n",
      "Train:  0.9827375556694123\n",
      "Test:  0.7365269461077845\n"
     ]
    }
   ],
   "source": [
    "print('\\nLinear Support Vector Classifier:')\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)\n",
    "print('Train: ',lsvc.score(features_train, labels_train))\n",
    "print('Test: ',lsvc.score(features_test, labels_test))\n",
    "\n",
    "\n",
    "print('\\nGaussuan Naive Bayes:')\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train, labels_train)\n",
    "print('Train: ',gnb.score(features_train, labels_train))\n",
    "print('Test: ',gnb.score(features_test, labels_test))\n",
    "\n",
    "\n",
    "print('\\nLogistic Regression:')\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, labels_train)\n",
    "print('Train: ',lr.score(features_train, labels_train))\n",
    "print('Test: ',lr.score(features_test, labels_test))\n",
    "\n",
    "\n",
    "print('\\nRandom Forest Classifier:')\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(features_train, labels_train)\n",
    "print('Train: ',rfc.score(features_train, labels_train))\n",
    "print('Test: ',rfc.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb459a-7204-4be6-abb3-272c6de7e094",
   "metadata": {},
   "source": [
    "### Prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7535429-6117-4e25-bf83-9e2c5196f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = create_features(tweets, 'text_ps', 3300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff59005e-cb16-4022-80d1-f57e57206b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['is_sarcastic_lsvc'] = lsvc.predict(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa252ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['is_sarcastic_lr'] = lr.predict(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8953ba5b-4f2e-40a6-8007-58e942b58e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob_desc</th>\n",
       "      <th>Vader_desc</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>is_sarcastic_lsvc</th>\n",
       "      <th>is_sarcastic_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Defining a clear vision: how regulation impact...</td>\n",
       "      <td>1606238961076092928</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1606238961076092928</td>\n",
       "      <td>1453665282484998149</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1606238961076092928']</td>\n",
       "      <td>2022-12-23T10:43:05.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Defining a clear vision how regulation impacts...</td>\n",
       "      <td>[]</td>\n",
       "      <td>defin clear vision regul impact innov</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>@SammyMarkleReal The Industrial revolution bro...</td>\n",
       "      <td>1605768828016726016</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1606099866135932928</td>\n",
       "      <td>1391360513834209282</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>['1606099866135932928']</td>\n",
       "      <td>2022-12-23T01:30:22.000Z</td>\n",
       "      <td>1.585831e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>Industrial revolution brought everyone into ci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>industri revolut brought everyon citi back sus...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>@ellegist @danwaterfield According to the UK g...</td>\n",
       "      <td>1604919853084598272</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605247678845259777</td>\n",
       "      <td>1159804461839212544</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>['1605247678845259777']</td>\n",
       "      <td>2022-12-20T17:04:05.000Z</td>\n",
       "      <td>1.065047e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>According to government statistics land use ha...</td>\n",
       "      <td>[]</td>\n",
       "      <td>accord govern statist land use quit stabl sinc...</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>weak_negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Organic farming would be a solution to fight g...</td>\n",
       "      <td>1606244055033122817</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1606244055033122817</td>\n",
       "      <td>1097880624176816128</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1606244055033122817']</td>\n",
       "      <td>2022-12-23T11:03:19.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Organic would be a solution to fight global wa...</td>\n",
       "      <td>[#IMCAP]</td>\n",
       "      <td>organ would solut fight global warm possibl tr...</td>\n",
       "      <td>0.184091</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>weak_negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "296  Defining a clear vision: how regulation impact...  1606238961076092928   \n",
       "315  @SammyMarkleReal The Industrial revolution bro...  1605768828016726016   \n",
       "434  @ellegist @danwaterfield According to the UK g...  1604919853084598272   \n",
       "15   Organic farming would be a solution to fight g...  1606244055033122817   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "296   en       everyone  1606238961076092928  1453665282484998149   \n",
       "315   en       everyone  1606099866135932928  1391360513834209282   \n",
       "434   en       everyone  1605247678845259777  1159804461839212544   \n",
       "15    en       everyone  1606244055033122817  1097880624176816128   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "296  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "315  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
       "434  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
       "15   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "296  ['1606238961076092928']  2022-12-23T10:43:05.000Z                  NaN   \n",
       "315  ['1606099866135932928']  2022-12-23T01:30:22.000Z         1.585831e+18   \n",
       "434  ['1605247678845259777']  2022-12-20T17:04:05.000Z         1.065047e+08   \n",
       "15   ['1606244055033122817']  2022-12-23T11:03:19.000Z                  NaN   \n",
       "\n",
       "     ...                                             text_c  keywords  \\\n",
       "296  ...  Defining a clear vision how regulation impacts...        []   \n",
       "315  ...  Industrial revolution brought everyone into ci...        []   \n",
       "434  ...  According to government statistics land use ha...        []   \n",
       "15   ...  Organic would be a solution to fight global wa...  [#IMCAP]   \n",
       "\n",
       "                                               text_ps  TextBlob   Vader  \\\n",
       "296              defin clear vision regul impact innov  0.100000  0.5574   \n",
       "315  industri revolut brought everyon citi back sus...  0.000000 -0.5423   \n",
       "434  accord govern statist land use quit stabl sinc... -0.022222  0.0000   \n",
       "15   organ would solut fight global warm possibl tr...  0.184091 -0.1779   \n",
       "\n",
       "     TextBlob_desc     Vader_desc  is_sarcastic is_sarcastic_lsvc  \\\n",
       "296  weak_positive       positive             0                 0   \n",
       "315        neutral       negative             1                 0   \n",
       "434  weak_negative        neutral             0                 0   \n",
       "15   weak_positive  weak_negative             1                 0   \n",
       "\n",
       "    is_sarcastic_lr  \n",
       "296               0  \n",
       "315               0  \n",
       "434               0  \n",
       "15                0  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28300fd1-d6f9-4862-ad14-cad72141951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Original: @Celtic_Films Really I think a lot of it comes down to agriculture spreading from the middle east into europe \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Clear: Really I think a lot of it comes down to spreading from middle east into europe \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Steammed: realli think lot come spread middl east europ \n",
      " -------------------------------------------------------------------------------------------\n",
      "KeyWords: [] \n",
      " -------------------------------------------------------------------------------------------\n",
      "TextBlob:  0.0 neutral\n",
      "Vader:  0.0 neutral\n",
      "Sarcasm (lsvc):  0\n",
      "Sarcasm (lr):  0\n"
     ]
    }
   ],
   "source": [
    "##Checking Twitters\n",
    "\n",
    "n = 90\n",
    "print('Text Original:', tweets.loc[n, 'text'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "print('Text Clear:', tweets.loc[n, 'text_c'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('Text Steammed:', tweets.loc[n, 'text_ps'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('KeyWords:', tweets.loc[n, 'keywords'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('TextBlob: ',tweets.loc[n, 'TextBlob'], tweets.loc[n, 'TextBlob_desc'])\n",
    "print('Vader: ', tweets.loc[n, 'Vader'], tweets.loc[n, 'Vader_desc'])\n",
    "print('Sarcasm (lsvc): ', tweets.loc[n, 'is_sarcastic_lsvc'])\n",
    "print('Sarcasm (lr): ', tweets.loc[n, 'is_sarcastic_lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddf721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
