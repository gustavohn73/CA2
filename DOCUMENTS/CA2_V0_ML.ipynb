{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a2b37d-661a-4bec-84fc-6803d3f4519c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e79a4e90-9825-447a-ae88-c93f9505717c",
   "metadata": {},
   "source": [
    "http://localhost:8890/lab!pip install textblob\n",
    "!pip install vaderSentiment\n",
    "!pip install nltk\n",
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab86713-fd1a-4530-bbf1-218b9c04a44b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1089dd83-4193-43ae-ad4c-fda87e659897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,tweepy,csv,re, requests, json\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, re\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d86504-3bc1-443b-8827-e0f0e5e3291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d41d8-cd04-4906-a9c3-70c095b80bda",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30cfb27-cb88-4c26-9801-2f4e55e9cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "#Changing dir\n",
    "folder = 'ML'\n",
    "try:\n",
    "    os.chdir(f'{os.getcwd()}/{folder}')\n",
    "except:\n",
    "    dir = os.getcwd().replace(os.getcwd().split('/')[-1], folder)\n",
    "    os.chdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf0efa-7921-4ea7-a523-9661f26befd5",
   "metadata": {},
   "source": [
    "# Getting Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdb3bc",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c918993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token\n",
    "config = dotenv_values(\".env\")\n",
    "bearer_token = config['BEARER_TOKEN']\n",
    "\n",
    "#connections\n",
    "auth = tweepy.OAuth2BearerHandler({bearer_token})\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def get_tweet_v1(query, filename, max_n):\n",
    "    search_url = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "\n",
    "\n",
    "    file_name = f'{filename}.bz2'\n",
    "    \n",
    "    if os.path.exists(file_name) == False: #First checking if database exists\n",
    "        print(f'Getting tweets...')\n",
    "        \n",
    "        # Querying the API\n",
    "        json_response = connect_to_endpoint(search_url, query)\n",
    "        \n",
    "        tweets_dt = pd.DataFrame.from_dict(json_response['data'])\n",
    "        \n",
    "        try:\n",
    "            n_token = json_response['meta'][\"next_token\"]\n",
    "            n = 0\n",
    "            while n_token != 0 | n < max_n:\n",
    "                print(f'Next Token: {n} \\n {n_token}')\n",
    "                query_next = query\n",
    "                query_next['next_token'] = n_token\n",
    "                json_response = connect_to_endpoint(search_url, query_next)\n",
    "                tweets_n = pd.DataFrame.from_dict(json_response['data'])\n",
    "                tweets_dt = pd.concat([tweets_dt,tweets_n], ignore_index=True)\n",
    "\n",
    "                n += 1\n",
    "                n_token = json_response['meta'][\"next_token\"]\n",
    "\n",
    "        except:\n",
    "            print('Error to proceed')\n",
    "            \n",
    "        meta = json_response['meta']\n",
    "        #np.save(f'{filename}.npy', meta)\n",
    "        #print ('file Meta Saved')\n",
    " \n",
    "        #tweets_dt.to_csv(file_name, index=False,compression='bz2')\n",
    "        #print(f'{len(tweets_dt)} Tweets found and saved')\n",
    "        \n",
    "    else:\n",
    "        create_dt = time.strftime(\"%d/%m/%Y %H:%M:%S\",time.strptime(time.ctime(os.path.getmtime(file_name))))\n",
    "        print(f'Reading {file_name}, created at {create_dt}')\n",
    "        tweets_dt = pd.read_csv(file_name)\n",
    "        print(f'File with {len(tweets_dt)} Tweets')\n",
    "        \n",
    "    return tweets_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550dcf4c",
   "metadata": {},
   "source": [
    "## Countries\n",
    "\n",
    "Getting up to 1000 tweets each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3974d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets...\n",
      "Error to proceed\n",
      "file Meta Saved\n",
      "2 Tweets found and saved\n",
      "Getting tweets...\n",
      "Error to proceed\n",
      "file Meta Saved\n",
      "3 Tweets found and saved\n",
      "Getting tweets...\n",
      "Error to proceed\n",
      "file Meta Saved\n",
      "1 Tweets found and saved\n",
      "Getting tweets...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3l/89_chlsj4jsbhptfdm3q643w0000gn/T/ipykernel_82411/470891386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'tweets_{c}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tweet_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3l/89_chlsj4jsbhptfdm3q643w0000gn/T/ipykernel_82411/2221682732.py\u001b[0m in \u001b[0;36mget_tweet_v1\u001b[0;34m(query, filename, max_n)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_to_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtweets_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "countries = ['Austria', 'Belgium', 'Bulgaria', 'Cyprus', 'Czechia', 'Denmark', 'Finland', 'France', 'Germany', 'Hungary',\n",
    "        'Ireland', 'Italy', 'Latvia', 'Netherlands', 'Poland', 'Portugal', 'Romania', 'Spain','Sweden', 'Europe', 'UK']\n",
    "\n",
    "filename = 'tweets_agri_2.bz2'\n",
    "\n",
    "if os.path.exists(filename) == False: \n",
    "    for c in countries:\n",
    "\n",
    "        q = {\n",
    "        'query': f'agriculture {c} -is:retweet',\n",
    "        'max_results': 100,\n",
    "        'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "        'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "        'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "        'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "        }\n",
    "\n",
    "        fn = f'tweets_{c}'\n",
    "        t = get_tweet_v1(q, fn, 10)\n",
    "        t['country'] = c\n",
    "        if c == countries[0]:\n",
    "            tweets = t\n",
    "        else:\n",
    "            tweets = pd.concat([tweets, t], ignore_index=True)\n",
    "\n",
    "    tweets.to_csv(filename, index=False,compression='bz2')\n",
    "    print(f'File with {len(tweets)} saved.')\n",
    "\n",
    "else:\n",
    "    create_dt = time.strftime(\"%d/%m/%Y %H:%M:%S\",time.strptime(time.ctime(os.path.getmtime(filename))))\n",
    "    print(f'Reading {filename}, created at {create_dt}')\n",
    "    tweets = pd.read_csv(filename)\n",
    "    print(f'File with {len(tweets)} Tweets')\n",
    "    \n",
    "\n",
    "tweets.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aeddaa-cefe-4e2e-8de2-2da07673ba09",
   "metadata": {},
   "source": [
    "# Clean Your Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead89be-b008-457a-b756-743f9679d0a6",
   "metadata": {},
   "source": [
    "## Worlds extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e77d4845-61f5-473f-8c7d-10007e17c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(x, link, keyword, usernames):\n",
    "    list_of_lists =[]\n",
    "    if link == True:\n",
    "        list_of_links = []\n",
    "        words = x.split(' ')\n",
    "        for word in words:\n",
    "            if re.search('http', word):\n",
    "                list_of_links.append(re.split(\"\\W+\",word.lower()))\n",
    "        if len(list_of_links) > 0:\n",
    "            list_of_lists.append(list_of_links[0])\n",
    "    \n",
    "    if keyword == True:\n",
    "        list_of_keywords = []\n",
    "        words = x.split()\n",
    "        for word in words:\n",
    "            if word.startswith('#'):\n",
    "                list_of_keywords.append(word)\n",
    "        if len(list_of_keywords) > 0:\n",
    "            list_of_lists.append(list_of_keywords)\n",
    "            \n",
    "    if usernames == True:\n",
    "        list_of_usernames = []\n",
    "        words = x.split()\n",
    "        for word in words:\n",
    "            if word.startswith('@'):\n",
    "                list_of_usernames.append(word.lower().replace('@',''))\n",
    "        if len(list_of_usernames) > 0:\n",
    "            list_of_lists.append(list_of_usernames)\n",
    "    \n",
    "    return  [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "        \n",
    "# keyword extraction from tweets\n",
    "def get_keywords(x):\n",
    "    list_of_keywords = []\n",
    "    words = x.split()\n",
    "    for word in words:\n",
    "        if word.startswith('#'):\n",
    "            list_of_keywords.append(word)\n",
    "    return list_of_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "238c29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets.lang == 'en']\n",
    "tweets = tweets.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e75c4a2-c05a-4c40-96fb-e4a875f809bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = tweets['text'].apply(lambda tweet : clean_tweet(tweet, link = True, keyword = False, usernames = True))\n",
    "rem_list = [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "tweets['text_c'] = tweets['text'].apply( lambda tweet : ' '.join([word for word in re.split(\"\\W+\",tweet) if word.lower() not in rem_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02cf3a80-7754-49f6-ad1e-abc74bd2a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keywords'] = tweets['text'].apply( lambda tweet : get_keywords(tweet) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8735bc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>The headquarter of Food and Agriculture Organi...</td>\n",
       "      <td>1606197452314251266</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1606197452314251266</td>\n",
       "      <td>1258905310699425792</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1606197452314251266']</td>\n",
       "      <td>2022-12-23T07:58:08.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>headquarter of Food Organization of United Nat...</td>\n",
       "      <td>[#READ_MORE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Before we all start our holidays, we are pleas...</td>\n",
       "      <td>1605502032919506944</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605502032919506944</td>\n",
       "      <td>34932200</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605502032919506944']</td>\n",
       "      <td>2022-12-21T09:54:48.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "      <td>Before we all start our holidays we pleased to...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "174  The headquarter of Food and Agriculture Organi...  1606197452314251266   \n",
       "241  Before we all start our holidays, we are pleas...  1605502032919506944   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "174   en       everyone  1606197452314251266  1258905310699425792   \n",
       "241   en       everyone  1605502032919506944             34932200   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "174  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "241  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "174  ['1606197452314251266']  2022-12-23T07:58:08.000Z                  NaN   \n",
       "241  ['1605502032919506944']  2022-12-21T09:54:48.000Z                  NaN   \n",
       "\n",
       "    referenced_tweets  geo country  \\\n",
       "174               NaN  NaN  France   \n",
       "241               NaN  NaN  German   \n",
       "\n",
       "                                                text_c      keywords  \n",
       "174  headquarter of Food Organization of United Nat...  [#READ_MORE]  \n",
       "241  Before we all start our holidays we pleased to...            []  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3aacee4f-7872-4d82-9c7d-e26b40459c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD:  @Nien72521217 @divyanshu3pathi The per Capita story doesn't correlate\n",
      "\n",
      "When I see 1000 AD, W Europe didn't have trade routes established, didn't have industrial revolution. Had largely constrained agriculture due to nature of their land. No known irrigation projects.\n",
      "\n",
      "Yet the per Capita is high? \n",
      "\n",
      "NEW:  per Capita story doesn correlate When I see 1000 AD W Europe didn have routes established didn have industrial revolution Had largely constrained due to nature of their land No known irrigation projects Yet per Capita is high\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "print('OLD: ', tweets['text'][n], '\\n')\n",
    "print('NEW: ', tweets['text_c'][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05495ec4-c735-4de4-ac3c-97ec5336f5aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PoterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d017ded-762a-4d2e-83a1-5c77ddd7a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the stopwords into the object named as \"stop_words\"\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Store the string.punctuation into an object punct\n",
    "punct = string.punctuation\n",
    "\n",
    "# Initialise an object using a method PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22f436cc-944d-421b-9e5f-b0d8b9db2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stremming(df, text_col, name_new_col):\n",
    "    # Store the column of the dataframe named as \"text\"\n",
    "    X = df[text_col]\n",
    "    cleaned_data=[]\n",
    "    # For loop from first value to length(X), ^a-zA-Z means include small and capital case letters\n",
    "    for i in range(len(X)):\n",
    "        text = re.sub('[^a-zA-Z]', ' ', X.iloc[i])\n",
    "        text = text.lower().split()\n",
    "        text = [stemmer.stem(word) for word in text if (word not in stop_words) and (word not in punct)]\n",
    "        text = ' '.join(text)\n",
    "        df.loc[ i ,name_new_col] = text\n",
    "    print('Stremmer done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4daa44e1-e9b6-45e9-9558-4ed03ce04eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stremmer done!\n"
     ]
    }
   ],
   "source": [
    "stremming(tweets, 'text_c', 'text_ps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bf02984-820b-4a28-8f1a-dd801d25c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knowledge of how to make pottery spread like wildfire between the hunter-gatherers of Stone Age Europe, covering thousands of miles in a few hundred years, much faster than agriculture https://t.co/Iu2YACvIGN \n",
      "\n",
      "knowledg make potteri spread like wildfir hunter gather stone age europ cover thousand mile hundr much faster \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tweets['text'][0], '\\n')\n",
    "print(tweets['text_ps'][0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75f0ff-efcc-4bc1-8f83-5cfe08074244",
   "metadata": {},
   "source": [
    "## Sentiment Analyzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c6b817-f690-4816-9bb7-eca288a23508",
   "metadata": {},
   "source": [
    "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. [link](https://textblob.readthedocs.io/en/dev/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65ef6d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>@TAH_Sci You are speaking to a sneaky reader o...</td>\n",
       "      <td>1605869709844439040</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605886458937720836</td>\n",
       "      <td>1578305394</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605886458937720836']</td>\n",
       "      <td>2022-12-22T11:22:22.000Z</td>\n",
       "      <td>816003098.0</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '160587271910641...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>You speaking to a sneaky reader of Farmers Gua...</td>\n",
       "      <td>[]</td>\n",
       "      <td>speak sneaki reader farmer guardian farmer wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Thank you to Minister @MartinHeydonFG for atte...</td>\n",
       "      <td>1604806390282862599</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604806390282862599</td>\n",
       "      <td>1235536533077270530</td>\n",
       "      <td>{'retweet_count': 2, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604806390282862599']</td>\n",
       "      <td>2022-12-19T11:50:33.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'place_id': 'cbd95de037c865b4'}</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Thank you to Minister for attending demonstrat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>thank minist attend demonstr member agri guard...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "336  @TAH_Sci You are speaking to a sneaky reader o...  1605869709844439040   \n",
       "153  Thank you to Minister @MartinHeydonFG for atte...  1604806390282862599   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "336   en       everyone  1605886458937720836           1578305394   \n",
       "153   en       everyone  1604806390282862599  1235536533077270530   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "336  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "153  {'retweet_count': 2, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "336  ['1605886458937720836']  2022-12-22T11:22:22.000Z          816003098.0   \n",
       "153  ['1604806390282862599']  2022-12-19T11:50:33.000Z                  NaN   \n",
       "\n",
       "                                     referenced_tweets  \\\n",
       "336  [{'type': 'replied_to', 'id': '160587271910641...   \n",
       "153                                                NaN   \n",
       "\n",
       "                                  geo  country  \\\n",
       "336                               NaN       UK   \n",
       "153  {'place_id': 'cbd95de037c865b4'}  Ireland   \n",
       "\n",
       "                                                text_c keywords  \\\n",
       "336  You speaking to a sneaky reader of Farmers Gua...       []   \n",
       "153  Thank you to Minister for attending demonstrat...       []   \n",
       "\n",
       "                                               text_ps  \n",
       "336  speak sneaki reader farmer guardian farmer wee...  \n",
       "153  thank minist attend demonstr member agri guard...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be6f0424-270d-4d33-a4d2-a561f9dc4d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Despite the war, the #wheat harvest ðŸŒ¾ in #Ukra...</td>\n",
       "      <td>1605568824371191809</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605568824371191809</td>\n",
       "      <td>1090218748282310657</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605568824371191809']</td>\n",
       "      <td>2022-12-21T14:20:12.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>Despite wheat harvest in has been larger than ...</td>\n",
       "      <td>[#wheat, #Ukraine]</td>\n",
       "      <td>despit wheat harvest larger expect tell</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>What do farmers think of the #NewCAP?\\n\\nðŸŽ§ In ...</td>\n",
       "      <td>1605225822683820033</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605225822683820033</td>\n",
       "      <td>2885085044</td>\n",
       "      <td>{'retweet_count': 7, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605225822683820033']</td>\n",
       "      <td>2022-12-20T15:37:14.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "      <td>What farmers think of NewCAP In new episode of...</td>\n",
       "      <td>[#NewCAP?, #Food4EU]</td>\n",
       "      <td>farmer think newcap new episod food europ podc...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "388  Despite the war, the #wheat harvest ðŸŒ¾ in #Ukra...  1605568824371191809   \n",
       "68   What do farmers think of the #NewCAP?\\n\\nðŸŽ§ In ...  1605225822683820033   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "388   en       everyone  1605568824371191809  1090218748282310657   \n",
       "68    en       everyone  1605225822683820033           2885085044   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "388  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "68   {'retweet_count': 7, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "388  ['1605568824371191809']  2022-12-21T14:20:12.000Z                  NaN   \n",
       "68   ['1605225822683820033']  2022-12-20T15:37:14.000Z                  NaN   \n",
       "\n",
       "    referenced_tweets  geo country  \\\n",
       "388               NaN  NaN      UK   \n",
       "68                NaN  NaN  Europe   \n",
       "\n",
       "                                                text_c              keywords  \\\n",
       "388  Despite wheat harvest in has been larger than ...    [#wheat, #Ukraine]   \n",
       "68   What farmers think of NewCAP In new episode of...  [#NewCAP?, #Food4EU]   \n",
       "\n",
       "                                               text_ps  TextBlob   Vader  \n",
       "388            despit wheat harvest larger expect tell  0.000000  0.0000  \n",
       "68   farmer think newcap new episod food europ podc...  0.136364 -0.2732  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tweets.index:\n",
    "    text = tweets.loc[i,'text_ps']\n",
    "    tweets.loc[i, 'TextBlob'] = TextBlob(text).sentiment.polarity\n",
    "    #print(TextBlob(text).sentiment.polarity)\n",
    "    tweets.loc[i, 'Vader'] = SentimentIntensityAnalyzer().polarity_scores(text)['compound']\n",
    "    #print(SentimentIntensityAnalyzer().polarity_scores(text)['compound'], '\\n')\n",
    "    \n",
    "tweets.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20692767-6953-4c5a-afc3-c572133f1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(df, col):\n",
    "\n",
    "    polarity = 0\n",
    "    neutral = 0\n",
    "    wpositive = 0\n",
    "    positive = 0\n",
    "    spositive = 0\n",
    "    wnegative = 0\n",
    "    negative = 0\n",
    "    snegative = 0\n",
    "     \n",
    "    for t in df.index:\n",
    "        \n",
    "        v = df.loc[t, col]\n",
    "        polarity += v  # adding up polarities to find the average later\n",
    "\n",
    "        if (v == 0):  # adding reaction of how people are reacting to find average later\n",
    "            neutral += 1\n",
    "            desc = 'neutral'\n",
    "        elif (v > 0 and v <= 0.3):\n",
    "            wpositive += 1\n",
    "            desc ='weak_positive'\n",
    "        elif (v > 0.3 and v <= 0.6):\n",
    "            positive += 1\n",
    "            desc = 'positive'\n",
    "        elif (v > 0.6 and v <= 1):\n",
    "            spositive += 1\n",
    "            desc = 'strong_positive'\n",
    "        elif (v > -0.3 and v <= 0):\n",
    "            wnegative += 1\n",
    "            desc = 'weak_negative'\n",
    "        elif (v > -0.6 and v <= -0.3):\n",
    "            negative += 1\n",
    "            desc = 'negative'\n",
    "        elif (v > -1 and v <= -0.6):\n",
    "            snegative += 1\n",
    "            desc = 'strong_negative'\n",
    "         \n",
    "        df.loc[t, f'{col}_desc'] = desc\n",
    "        \n",
    "\n",
    "    return {'polarity_sum':polarity,\n",
    "            'polarity_mean':(polarity / len(df)),\n",
    "            'neutral':neutral,\n",
    "            'strong_positive':spositive,\n",
    "            'positive':positive,\n",
    "            'weak_positive':wpositive,\n",
    "            'weak_negative':wnegative,\n",
    "            'negative':negative,\n",
    "            'strong_negative':snegative}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90a9864e-2155-4fc0-9154-82d2544a2da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity_sum': 43.62266860916862,\n",
       " 'polarity_mean': 0.06837408872910442,\n",
       " 'neutral': 265,\n",
       " 'strong_positive': 18,\n",
       " 'positive': 68,\n",
       " 'weak_positive': 174,\n",
       " 'weak_negative': 91,\n",
       " 'negative': 13,\n",
       " 'strong_negative': 8}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_polarity(tweets,'TextBlob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58ccdc01-f6c2-4a3f-9e1a-ea8688effb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity_sum': 109.63159999999992,\n",
       " 'polarity_mean': 0.1718363636363635,\n",
       " 'neutral': 209,\n",
       " 'strong_positive': 99,\n",
       " 'positive': 154,\n",
       " 'weak_positive': 70,\n",
       " 'weak_negative': 39,\n",
       " 'negative': 42,\n",
       " 'strong_negative': 25}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_polarity(tweets,'Vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db5c2e3c-a707-450f-bb85-c7327834ad00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob_desc</th>\n",
       "      <th>Vader_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>The Department of Agriculture, Environment and...</td>\n",
       "      <td>1605172950457618432</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605172950457618432</td>\n",
       "      <td>4849821129</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605172950457618432']</td>\n",
       "      <td>2022-12-20T12:07:08.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>Department of Rural Affairs DAERA has announce...</td>\n",
       "      <td>[]</td>\n",
       "      <td>depart rural affair daera announc public data ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "470  The Department of Agriculture, Environment and...  1605172950457618432   \n",
       "\n",
       "    lang reply_settings                   id   author_id  \\\n",
       "470   en       everyone  1605172950457618432  4849821129   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "470  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "470  ['1605172950457618432']  2022-12-20T12:07:08.000Z                  NaN   \n",
       "\n",
       "    referenced_tweets  geo country  \\\n",
       "470               NaN  NaN      UK   \n",
       "\n",
       "                                                text_c keywords  \\\n",
       "470  Department of Rural Affairs DAERA has announce...       []   \n",
       "\n",
       "                                               text_ps  TextBlob  Vader  \\\n",
       "470  depart rural affair daera announc public data ...       0.0    0.0   \n",
       "\n",
       "    TextBlob_desc Vader_desc  \n",
       "470       neutral    neutral  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "257a80b8-1d52-4e9e-9094-1c9dfe9114c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Original: @RonFilipkowski Ron, you are missing the point.  Putin doesnâ€™t want peace, Putin wants Ukraineâ€™s oil, gas and agriculture (wheat) to have a stranglehold on Europe!!! \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Clear: Ron you missing point Putin doesn want peace Putin wants s oil gas wheat to have a stranglehold on Europe \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Steammed: ron miss point putin want peac putin want oil ga wheat stranglehold europ \n",
      " -------------------------------------------------------------------------------------------\n",
      "KeyWords: [] \n",
      " -------------------------------------------------------------------------------------------\n",
      "TextBlob:  0.0 neutral\n",
      "Vader:  0.0 neutral\n"
     ]
    }
   ],
   "source": [
    "##Checking Twitters\n",
    "\n",
    "n = 3\n",
    "print('Text Original:', tweets.loc[n, 'text'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "print('Text Clear:', tweets.loc[n, 'text_c'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('Text Steammed:', tweets.loc[n, 'text_ps'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('KeyWords:', tweets.loc[n, 'keywords'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('TextBlob: ',tweets.loc[n, 'TextBlob'], tweets.loc[n, 'TextBlob_desc'])\n",
    "print('Vader: ', tweets.loc[n, 'Vader'], tweets.loc[n, 'Vader_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8add63f-2230-4811-941a-d4fd1e8ea7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob_desc</th>\n",
       "      <th>Vader_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>knowledg make potteri spread like wildfir hunt...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>per capita stori correl see ad w europ rout es...</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>everyth need chang villag settl illo tempor hu...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>neutral</td>\n",
       "      <td>strong_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>ron miss point putin want peac putin want oil ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>russia one encourag us aid amp assist help peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>[]</td>\n",
       "      <td>ye reform set safe amp legal rout process refu...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>positive</td>\n",
       "      <td>strong_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>[#BiggestJobonEarth, #agriculture]</td>\n",
       "      <td>case miss catch episod biggestjobonearth podca...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>negative</td>\n",
       "      <td>weak_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>[]</td>\n",
       "      <td>respons contribut transform new strategi</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>[]</td>\n",
       "      <td>eu minist call rethink free</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>[#RemoteSensing, #ComputerScience, #hyperspect...</td>\n",
       "      <td>posit predict model hyperspectr satellit imag ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              keywords  \\\n",
       "0                                                   []   \n",
       "1                                                   []   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "633                                                 []   \n",
       "634                 [#BiggestJobonEarth, #agriculture]   \n",
       "635                                                 []   \n",
       "636                                                 []   \n",
       "637  [#RemoteSensing, #ComputerScience, #hyperspect...   \n",
       "\n",
       "                                               text_ps  TextBlob   Vader  \\\n",
       "0    knowledg make potteri spread like wildfir hunt...  0.200000  0.3612   \n",
       "1    per capita stori correl see ad w europ rout es...  0.017500  0.0000   \n",
       "2    everyth need chang villag settl illo tempor hu...  0.000000  0.7717   \n",
       "3    ron miss point putin want peac putin want oil ...  0.000000  0.0000   \n",
       "4    russia one encourag us aid amp assist help peo...  0.000000  0.4019   \n",
       "..                                                 ...       ...     ...   \n",
       "633  ye reform set safe amp legal rout process refu...  0.350000  0.8689   \n",
       "634  case miss catch episod biggestjobonearth podca... -0.500000  0.1531   \n",
       "635           respons contribut transform new strategi  0.136364  0.0000   \n",
       "636                        eu minist call rethink free  0.400000  0.5106   \n",
       "637  posit predict model hyperspectr satellit imag ...  0.000000  0.0000   \n",
       "\n",
       "     TextBlob_desc       Vader_desc  \n",
       "0    weak_positive         positive  \n",
       "1    weak_positive          neutral  \n",
       "2          neutral  strong_positive  \n",
       "3          neutral          neutral  \n",
       "4          neutral         positive  \n",
       "..             ...              ...  \n",
       "633       positive  strong_positive  \n",
       "634       negative    weak_positive  \n",
       "635  weak_positive          neutral  \n",
       "636       positive         positive  \n",
       "637        neutral          neutral  \n",
       "\n",
       "[638 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[:, -6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e7c79-0879-49b5-89f8-22752f114ae9",
   "metadata": {},
   "source": [
    "## Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3f3bff5-51d0-4991-bac3-4f6f98cfc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "807c9b2e-6cc2-467d-8c8e-25a30ea4a224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22179</th>\n",
       "      <td>depressed nra member half-hoping son will acci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "22179  depressed nra member half-hoping son will acci...             1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('sarcasm_headlines.bz2')\n",
    "news.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "144ff0f9-d5f9-4a1a-bc6b-1937bfcda176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline        False\n",
      "is_sarcastic    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(news.isnull().any(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8c5cabd-ac81-4f61-bd88-8532fba63e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stremmer done!\n"
     ]
    }
   ],
   "source": [
    "stremming(news, 'headline', 'headline_ps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a35696a6-e876-4c86-99c8-28c31e2f7156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline_ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>report: spider</td>\n",
       "      <td>1</td>\n",
       "      <td>report spider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22605</th>\n",
       "      <td>blood-sucking lamprey forced to make awkward s...</td>\n",
       "      <td>1</td>\n",
       "      <td>blood suck lamprey forc make awkward small tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic  \\\n",
       "5178                                      report: spider             1   \n",
       "22605  blood-sucking lamprey forced to make awkward s...             1   \n",
       "\n",
       "                                             headline_ps  \n",
       "5178                                       report spider  \n",
       "22605  blood suck lamprey forc make awkward small tal...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89da3d5f-ade0-4bbb-9347-27fda1d84d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, col, max_feat):\n",
    "    features = df[col]\n",
    "\n",
    "    # vectorizing the data with maximum features\n",
    "    tv = TfidfVectorizer(max_features = max_feat)\n",
    "    features = list(features)\n",
    "    features = tv.fit_transform(features).toarray()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6eadf98f-4d8c-4ba3-8db8-6435afb36ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = create_features(news, 'headline_ps', 3300)\n",
    "labels = news['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56eacc4a-5c35-4830-89b3-8657354f2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2d6160f-3ab9-45f9-99c1-58a414f2f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Support Vector Classifier:\n",
      "Train:  0.8462933039057265\n",
      "Test:  0.7784431137724551\n",
      "\n",
      "Gaussuan Naive Bayes:\n",
      "Train:  0.750679856540417\n",
      "Test:  0.7215568862275449\n",
      "\n",
      "Logistic Regression:\n",
      "Train:  0.8314349899499468\n",
      "Test:  0.782185628742515\n",
      "\n",
      "Random Forest Classifier:\n",
      "Train:  0.9827375556694123\n",
      "Test:  0.7365269461077845\n"
     ]
    }
   ],
   "source": [
    "print('\\nLinear Support Vector Classifier:')\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)\n",
    "print('Train: ',lsvc.score(features_train, labels_train))\n",
    "print('Test: ',lsvc.score(features_test, labels_test))\n",
    "\n",
    "\n",
    "print('\\nGaussuan Naive Bayes:')\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train, labels_train)\n",
    "print('Train: ',gnb.score(features_train, labels_train))\n",
    "print('Test: ',gnb.score(features_test, labels_test))\n",
    "\n",
    "\n",
    "print('\\nLogistic Regression:')\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, labels_train)\n",
    "print('Train: ',lr.score(features_train, labels_train))\n",
    "print('Test: ',lr.score(features_test, labels_test))\n",
    "\n",
    "\n",
    "print('\\nRandom Forest Classifier:')\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(features_train, labels_train)\n",
    "print('Train: ',rfc.score(features_train, labels_train))\n",
    "print('Test: ',rfc.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb459a-7204-4be6-abb3-272c6de7e094",
   "metadata": {},
   "source": [
    "### Prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7535429-6117-4e25-bf83-9e2c5196f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = create_features(tweets, 'text_ps', 3300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff59005e-cb16-4022-80d1-f57e57206b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['is_sarcastic_lsvc'] = lsvc.predict(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fbfa84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['is_sarcastic_lr'] = lr.predict(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8953ba5b-4f2e-40a6-8007-58e942b58e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>text_c</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_ps</th>\n",
       "      <th>TextBlob</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob_desc</th>\n",
       "      <th>Vader_desc</th>\n",
       "      <th>is_sarcastic_lsvc</th>\n",
       "      <th>is_sarcastic_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>@GermanyDiplo @DrSJaishankar @ABaerbock Cpec r...</td>\n",
       "      <td>1599737279890661377</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1604820915136696322</td>\n",
       "      <td>1566407156576002050</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1604820915136696322']</td>\n",
       "      <td>2022-12-19T12:48:16.000Z</td>\n",
       "      <td>453030125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>German</td>\n",
       "      <td>Cpec rpec projects electric gas dam sugar stee...</td>\n",
       "      <td>[]</td>\n",
       "      <td>cpec rpec project electr ga dam sugar steel mi...</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>weak_positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>The future of food - Is sustainable agricultur...</td>\n",
       "      <td>1605529594471161857</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605529594471161857</td>\n",
       "      <td>1099450872784797696</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605529594471161857']</td>\n",
       "      <td>2022-12-21T11:44:19.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>future of food Is sustainable possible in Euro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>futur food sustain possibl europ via</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>#EuropeanUnion #France\\nFlashback on ECJ Cases...</td>\n",
       "      <td>1603993929959067653</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1603993929959067653</td>\n",
       "      <td>1035079865412845568</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1603993929959067653']</td>\n",
       "      <td>2022-12-17T06:02:08.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>France</td>\n",
       "      <td>EuropeanUnion France Flashback on Cases C 596 ...</td>\n",
       "      <td>[#EuropeanUnion, #France, #ECJ(EuropeanCourtof...</td>\n",
       "      <td>europeanunion franc flashback case c commiss v...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>New blog ðŸ“£\\n\\nAccording to a recent study, #fa...</td>\n",
       "      <td>1605891783866597376</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1605891783866597376</td>\n",
       "      <td>280867595</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>['1605891783866597376']</td>\n",
       "      <td>2022-12-22T11:43:31.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>UK</td>\n",
       "      <td>New blog According to a recent study farmers m...</td>\n",
       "      <td>[#farmers, #Agriculture]</td>\n",
       "      <td>new blog accord recent studi farmer make tini ...</td>\n",
       "      <td>-0.058712</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>weak_negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      conversation_id  \\\n",
       "258  @GermanyDiplo @DrSJaishankar @ABaerbock Cpec r...  1599737279890661377   \n",
       "55   The future of food - Is sustainable agricultur...  1605529594471161857   \n",
       "223  #EuropeanUnion #France\\nFlashback on ECJ Cases...  1603993929959067653   \n",
       "335  New blog ðŸ“£\\n\\nAccording to a recent study, #fa...  1605891783866597376   \n",
       "\n",
       "    lang reply_settings                   id            author_id  \\\n",
       "258   en       everyone  1604820915136696322  1566407156576002050   \n",
       "55    en       everyone  1605529594471161857  1099450872784797696   \n",
       "223   en       everyone  1603993929959067653  1035079865412845568   \n",
       "335   en       everyone  1605891783866597376            280867595   \n",
       "\n",
       "                                        public_metrics  \\\n",
       "258  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "55   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "223  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "335  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "      edit_history_tweet_ids                created_at  in_reply_to_user_id  \\\n",
       "258  ['1604820915136696322']  2022-12-19T12:48:16.000Z          453030125.0   \n",
       "55   ['1605529594471161857']  2022-12-21T11:44:19.000Z                  NaN   \n",
       "223  ['1603993929959067653']  2022-12-17T06:02:08.000Z                  NaN   \n",
       "335  ['1605891783866597376']  2022-12-22T11:43:31.000Z                  NaN   \n",
       "\n",
       "     ... country                                             text_c  \\\n",
       "258  ...  German  Cpec rpec projects electric gas dam sugar stee...   \n",
       "55   ...  Europe  future of food Is sustainable possible in Euro...   \n",
       "223  ...  France  EuropeanUnion France Flashback on Cases C 596 ...   \n",
       "335  ...      UK  New blog According to a recent study farmers m...   \n",
       "\n",
       "                                              keywords  \\\n",
       "258                                                 []   \n",
       "55                                                  []   \n",
       "223  [#EuropeanUnion, #France, #ECJ(EuropeanCourtof...   \n",
       "335                           [#farmers, #Agriculture]   \n",
       "\n",
       "                                               text_ps  TextBlob   Vader  \\\n",
       "258  cpec rpec project electr ga dam sugar steel mi...  0.077778  0.4404   \n",
       "55                futur food sustain possibl europ via  0.000000  0.0000   \n",
       "223  europeanunion franc flashback case c commiss v...  0.000000  0.0000   \n",
       "335  new blog accord recent studi farmer make tini ... -0.058712  0.4404   \n",
       "\n",
       "     TextBlob_desc  Vader_desc is_sarcastic_lsvc is_sarcastic_lr  \n",
       "258  weak_positive    positive                 0               0  \n",
       "55         neutral     neutral                 0               0  \n",
       "223        neutral     neutral                 0               0  \n",
       "335  weak_negative    positive                 1               1  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28300fd1-d6f9-4862-ad14-cad72141951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Original: @andersen_inger @UrosBrezan @SLOtoUN @UNEP_Europe @rs_mop @MOEPPMKD I have solutions to increase water sources reducing atmosphere temperature with 15C stopping glaciers melting, eliminating smog of Santiago, to prevent forest fires, to make grassland, agriculture land, forest, Ã®n slop,desert, mechanized, efficient, cheap Please send answer Thank \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Clear: I have solutions to increase water sources reducing atmosphere temperature with 15C stopping glaciers melting eliminating smog of Santiago to prevent forest fires to make grassland land forest Ã®n slop desert mechanized efficient cheap Please send answer Thank \n",
      " -------------------------------------------------------------------------------------------\n",
      "Text Steammed: solut increas water sourc reduc atmospher temperatur c stop glacier melt elimin smog santiago prevent forest fire make grassland land forest n slop desert mechan effici cheap pleas send answer thank \n",
      " -------------------------------------------------------------------------------------------\n",
      "KeyWords: [] \n",
      " -------------------------------------------------------------------------------------------\n",
      "TextBlob:  0.4 positive\n",
      "Vader:  -0.4939 negative\n",
      "Sarcasm (lsvc):  0\n",
      "Sarcasm (lr):  0\n"
     ]
    }
   ],
   "source": [
    "##Checking Twitters\n",
    "\n",
    "n = 101\n",
    "print('Text Original:', tweets.loc[n, 'text'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "print('Text Clear:', tweets.loc[n, 'text_c'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('Text Steammed:', tweets.loc[n, 'text_ps'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('KeyWords:', tweets.loc[n, 'keywords'], '\\n',\n",
    "     '-------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('TextBlob: ',tweets.loc[n, 'TextBlob'], tweets.loc[n, 'TextBlob_desc'])\n",
    "print('Vader: ', tweets.loc[n, 'Vader'], tweets.loc[n, 'Vader_desc'])\n",
    "print('Sarcasm (lsvc): ', tweets.loc[n, 'is_sarcastic_lsvc'])\n",
    "print('Sarcasm (lr): ', tweets.loc[n, 'is_sarcastic_lr'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
